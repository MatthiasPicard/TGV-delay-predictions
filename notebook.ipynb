{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif\n",
    "- prédire le temps de retard moyen des trains sur une ligne sur un mois\n",
    "--> predire retard_moyen_arrivee? ou retard_moyen_tous_trains_arrivee?\n",
    "- prédire la cause du retard (en pourcentage pour chaque cause potentielle) sur une ligne sur un mois\n",
    "\n",
    "- alternative --> fusionner toutes les lignes sur un mois et predire sur un mois pour toute les lignes à la fois\n",
    "\n",
    "## Questions\n",
    "\n",
    "### faire deux modèles distincts ou dépendants pour ces deux problématique?\n",
    "- si dépendant --> NN avec une regression et des classifs en sortie\n",
    "- si indépendant --> on a le choix\n",
    "- mix --> on prédit la regression d'abord puis la classif en se servant des resultats de la regression ( ou inversement)\n",
    "\n",
    "### Modèles independants pour chaque ligne de train ou tout lier?\n",
    "- si indépendant, plus facile à gérer on peut facilement créer des séries temporelles, mais beaucoup(beaucoup) de modèle à créer\n",
    "- si liée, on peut exploiter des correlations en plus et on n'a qu'un modèle, mais on doit encoder l'année, le mois et toutes les gares (avec un one hot ça va faire beaucoup de colonne, avec un ordinal on introduit une relation d'ordre qui n'existe pas, remarque on aurait pas ce soucis avec des arbres de décision)\n",
    "\n",
    "### Analyse à faire \n",
    "- autocorrelation mois et année sur le temps de retard et les causes du retard\n",
    "- regarder correlation retard moyen entre paris-lyon et lyon-paris (pour tout les couples de gares)\n",
    "- pleins d'autres trucs qui nous permettront d'enlever/modifier/rajouter des colonnes\n",
    "\n",
    "### Données qu'on peut rajouter\n",
    "- longueur de chaque lignes (pas forcement nécessaire?)\n",
    "\n",
    "### Infos importantes\n",
    "- https://www.data.gouv.fr/fr/datasets/regularite-mensuelle-tgv-par-liaisons/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"regularite-mensuelle-tgv-aqst.csv\",encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8154 entries, 0 to 8153\n",
      "Data columns (total 26 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   date                                  8154 non-null   object \n",
      " 1   service                               8154 non-null   object \n",
      " 2   gare_depart                           8154 non-null   object \n",
      " 3   gare_arrivee                          8154 non-null   object \n",
      " 4   duree_moyenne                         8154 non-null   int64  \n",
      " 5   nb_train_prevu                        8154 non-null   int64  \n",
      " 6   nb_annulation                         8154 non-null   int64  \n",
      " 7   commentaire_annulation                0 non-null      float64\n",
      " 8   nb_train_depart_retard                8154 non-null   int64  \n",
      " 9   retard_moyen_depart                   8154 non-null   float64\n",
      " 10  retard_moyen_tous_trains_depart       8154 non-null   float64\n",
      " 11  commentaire_retards_depart            0 non-null      float64\n",
      " 12  nb_train_retard_arrivee               8154 non-null   int64  \n",
      " 13  retard_moyen_arrivee                  8154 non-null   float64\n",
      " 14  retard_moyen_tous_trains_arrivee      8154 non-null   float64\n",
      " 15  commentaires_retard_arrivee           698 non-null    object \n",
      " 16  nb_train_retard_sup_15                8154 non-null   int64  \n",
      " 17  retard_moyen_trains_retard_sup15      8154 non-null   float64\n",
      " 18  nb_train_retard_sup_30                8154 non-null   int64  \n",
      " 19  nb_train_retard_sup_60                8154 non-null   int64  \n",
      " 20  prct_cause_externe                    8154 non-null   float64\n",
      " 21  prct_cause_infra                      8154 non-null   float64\n",
      " 22  prct_cause_gestion_trafic             8154 non-null   float64\n",
      " 23  prct_cause_materiel_roulant           8154 non-null   float64\n",
      " 24  prct_cause_gestion_gare               8154 non-null   float64\n",
      " 25  prct_cause_prise_en_charge_voyageurs  8154 non-null   float64\n",
      "dtypes: float64(13), int64(8), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       28.436735\n",
       "1       21.524020\n",
       "2       55.692308\n",
       "3       48.623077\n",
       "4       12.405164\n",
       "          ...    \n",
       "8149    30.157302\n",
       "8150    76.688889\n",
       "8151    45.841146\n",
       "8152    41.487213\n",
       "8153    42.007752\n",
       "Name: retard_moyen_arrivee, Length: 8154, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"retard_moyen_arrivee\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        6.511118\n",
       "1        5.696096\n",
       "2        7.578947\n",
       "3        6.790686\n",
       "4        3.346487\n",
       "          ...    \n",
       "8149     7.689898\n",
       "8150    14.824264\n",
       "8151     8.650349\n",
       "8152    12.765753\n",
       "8153     7.251702\n",
       "Name: retard_moyen_tous_trains_arrivee, Length: 8154, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"retard_moyen_tous_trains_arrivee\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "59\n",
      "8154\n"
     ]
    }
   ],
   "source": [
    "print(len(set(df[\"gare_depart\"].tolist()))) #pd.get_dummies\n",
    "print(len(set(df[\"gare_arrivee\"].tolist()))) #pd.get_dummies\n",
    "print(len(df[\"date\"].tolist())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    # Add commands to clean dataframe\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.drop(\"commentaires_retard_arrivee\", axis=1) # str and not relevant for model\n",
    "    return df\n",
    "\n",
    "clean_df = clean_df(df) #Test\n",
    "# Dataset cleaning should be done on train and test set separately -> ensure reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_df.columns))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenghts of train/test: 7428/726\n",
      "split train/test: 91.1/8.9\n"
     ]
    }
   ],
   "source": [
    "def get_train_test_set(df):\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    for i, d in enumerate(df[\"date\"].tolist()):\n",
    "        month, day, year = d.split('/')\n",
    "        if int(year)<2023:\n",
    "            train_idx.append(i)\n",
    "        else:\n",
    "            test_idx.append(i)\n",
    "    \n",
    "    train_set = df.iloc[train_idx].copy(deep=True)\n",
    "    test_set = df.iloc[test_idx].copy(deep=True)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "train_set, test_set = get_train_test_set(df)\n",
    "\n",
    "\n",
    "split = [(len(train_idx)/len(df))*100, (len(test_idx)/len(df))*100]\n",
    "print(f\"Lenghts of train/test: {len(train_idx)}/{len(test_idx)}\")\n",
    "print(f\"split train/test: {round(split[0],2)}/{round(split[1],2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'International', 'National'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_set[\"service\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test with date transform to year, months over years, days"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

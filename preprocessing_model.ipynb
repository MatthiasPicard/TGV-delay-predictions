{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"regularite-mensuelle-tgv-aqst.csv\",encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'service', 'gare_depart', 'gare_arrivee', 'duree_moyenne',\n",
       "       'nb_train_prevu', 'nb_annulation', 'commentaire_annulation',\n",
       "       'nb_train_depart_retard', 'retard_moyen_depart',\n",
       "       'retard_moyen_tous_trains_depart', 'commentaire_retards_depart',\n",
       "       'nb_train_retard_arrivee', 'retard_moyen_arrivee',\n",
       "       'retard_moyen_tous_trains_arrivee', 'commentaires_retard_arrivee',\n",
       "       'nb_train_retard_sup_15', 'retard_moyen_trains_retard_sup15',\n",
       "       'nb_train_retard_sup_30', 'nb_train_retard_sup_60',\n",
       "       'prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic',\n",
       "       'prct_cause_materiel_roulant', 'prct_cause_gestion_gare',\n",
       "       'prct_cause_prise_en_charge_voyageurs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>service</th>\n",
       "      <th>gare_depart</th>\n",
       "      <th>gare_arrivee</th>\n",
       "      <th>duree_moyenne</th>\n",
       "      <th>nb_train_prevu</th>\n",
       "      <th>nb_annulation</th>\n",
       "      <th>commentaire_annulation</th>\n",
       "      <th>nb_train_depart_retard</th>\n",
       "      <th>retard_moyen_depart</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_train_retard_sup_15</th>\n",
       "      <th>retard_moyen_trains_retard_sup15</th>\n",
       "      <th>nb_train_retard_sup_30</th>\n",
       "      <th>nb_train_retard_sup_60</th>\n",
       "      <th>prct_cause_externe</th>\n",
       "      <th>prct_cause_infra</th>\n",
       "      <th>prct_cause_gestion_trafic</th>\n",
       "      <th>prct_cause_materiel_roulant</th>\n",
       "      <th>prct_cause_gestion_gare</th>\n",
       "      <th>prct_cause_prise_en_charge_voyageurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>BORDEAUX ST JEAN</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>141</td>\n",
       "      <td>870</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289</td>\n",
       "      <td>11.247809</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>6.511118</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>36.134454</td>\n",
       "      <td>31.092437</td>\n",
       "      <td>10.924370</td>\n",
       "      <td>15.966387</td>\n",
       "      <td>5.042017</td>\n",
       "      <td>0.840336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>LA ROCHELLE VILLE</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>165</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>5.696096</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>QUIMPER</td>\n",
       "      <td>220</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>9.501351</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>7.548387</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>26.923077</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>ST MALO</td>\n",
       "      <td>156</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>19.912500</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6.724757</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>ST PIERRE DES CORPS</td>\n",
       "      <td>61</td>\n",
       "      <td>391</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>7.796995</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3.346487</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>21.212121</td>\n",
       "      <td>42.424242</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>21.212121</td>\n",
       "      <td>6.060606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   service         gare_depart         gare_arrivee  duree_moyenne  \\\n",
       "0  1/1/2018  National    BORDEAUX ST JEAN   PARIS MONTPARNASSE            141   \n",
       "1  1/1/2018  National   LA ROCHELLE VILLE   PARIS MONTPARNASSE            165   \n",
       "2  1/1/2018  National  PARIS MONTPARNASSE              QUIMPER            220   \n",
       "3  1/1/2018  National  PARIS MONTPARNASSE              ST MALO            156   \n",
       "4  1/1/2018  National  PARIS MONTPARNASSE  ST PIERRE DES CORPS             61   \n",
       "\n",
       "   nb_train_prevu  nb_annulation  commentaire_annulation  \\\n",
       "0             870              5                     NaN   \n",
       "1             222              0                     NaN   \n",
       "2             248              1                     NaN   \n",
       "3             102              0                     NaN   \n",
       "4             391              2                     NaN   \n",
       "\n",
       "   nb_train_depart_retard  retard_moyen_depart  ...  nb_train_retard_sup_15  \\\n",
       "0                     289            11.247809  ...                     110   \n",
       "1                       8             2.875000  ...                      22   \n",
       "2                      37             9.501351  ...                      26   \n",
       "3                      12            19.912500  ...                       8   \n",
       "4                      61             7.796995  ...                      17   \n",
       "\n",
       "   retard_moyen_trains_retard_sup15  nb_train_retard_sup_30  \\\n",
       "0                          6.511118                      44   \n",
       "1                          5.696096                       5   \n",
       "2                          7.548387                      17   \n",
       "3                          6.724757                       6   \n",
       "4                          3.346487                       6   \n",
       "\n",
       "   nb_train_retard_sup_60  prct_cause_externe prct_cause_infra  \\\n",
       "0                       8           36.134454        31.092437   \n",
       "1                       0           15.384615        30.769231   \n",
       "2                       7           26.923077        38.461538   \n",
       "3                       4           23.076923        46.153846   \n",
       "4                       0           21.212121        42.424242   \n",
       "\n",
       "   prct_cause_gestion_trafic  prct_cause_materiel_roulant  \\\n",
       "0                  10.924370                    15.966387   \n",
       "1                  38.461538                    11.538462   \n",
       "2                  15.384615                    19.230769   \n",
       "3                   7.692308                    15.384615   \n",
       "4                   9.090909                    21.212121   \n",
       "\n",
       "   prct_cause_gestion_gare  prct_cause_prise_en_charge_voyageurs  \n",
       "0                 5.042017                              0.840336  \n",
       "1                 3.846154                              0.000000  \n",
       "2                 0.000000                              0.000000  \n",
       "3                 7.692308                              0.000000  \n",
       "4                 6.060606                              0.000000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                    0.000000\n",
       "prct_cause_materiel_roulant             0.000000\n",
       "prct_cause_gestion_trafic               0.000000\n",
       "prct_cause_infra                        0.000000\n",
       "prct_cause_externe                      0.000000\n",
       "nb_train_retard_sup_60                  0.000000\n",
       "nb_train_retard_sup_30                  0.000000\n",
       "retard_moyen_trains_retard_sup15        0.000000\n",
       "nb_train_retard_sup_15                  0.000000\n",
       "retard_moyen_tous_trains_arrivee        0.000000\n",
       "retard_moyen_arrivee                    0.000000\n",
       "prct_cause_gestion_gare                 0.000000\n",
       "nb_train_retard_arrivee                 0.000000\n",
       "retard_moyen_tous_trains_depart         0.000000\n",
       "retard_moyen_depart                     0.000000\n",
       "nb_train_depart_retard                  0.000000\n",
       "nb_annulation                           0.000000\n",
       "nb_train_prevu                          0.000000\n",
       "duree_moyenne                           0.000000\n",
       "gare_arrivee                            0.000000\n",
       "gare_depart                             0.000000\n",
       "service                                 0.000000\n",
       "prct_cause_prise_en_charge_voyageurs    0.000000\n",
       "commentaires_retard_arrivee             0.914398\n",
       "commentaire_annulation                  1.000000\n",
       "commentaire_retards_depart              1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isna().sum()/df.shape[0]).sort_values(ascending=True)  # Nan only in the comment columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>service</th>\n",
       "      <th>gare_depart</th>\n",
       "      <th>gare_arrivee</th>\n",
       "      <th>duree_moyenne</th>\n",
       "      <th>nb_train_prevu</th>\n",
       "      <th>nb_annulation</th>\n",
       "      <th>commentaire_annulation</th>\n",
       "      <th>nb_train_depart_retard</th>\n",
       "      <th>retard_moyen_depart</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_train_retard_sup_15</th>\n",
       "      <th>retard_moyen_trains_retard_sup15</th>\n",
       "      <th>nb_train_retard_sup_30</th>\n",
       "      <th>nb_train_retard_sup_60</th>\n",
       "      <th>prct_cause_externe</th>\n",
       "      <th>prct_cause_infra</th>\n",
       "      <th>prct_cause_gestion_trafic</th>\n",
       "      <th>prct_cause_materiel_roulant</th>\n",
       "      <th>prct_cause_gestion_gare</th>\n",
       "      <th>prct_cause_prise_en_charge_voyageurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, service, gare_depart, gare_arrivee, duree_moyenne, nb_train_prevu, nb_annulation, commentaire_annulation, nb_train_depart_retard, retard_moyen_depart, retard_moyen_tous_trains_depart, commentaire_retards_depart, nb_train_retard_arrivee, retard_moyen_arrivee, retard_moyen_tous_trains_arrivee, commentaires_retard_arrivee, nb_train_retard_sup_15, retard_moyen_trains_retard_sup15, nb_train_retard_sup_30, nb_train_retard_sup_60, prct_cause_externe, prct_cause_infra, prct_cause_gestion_trafic, prct_cause_materiel_roulant, prct_cause_gestion_gare, prct_cause_prise_en_charge_voyageurs]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]  # No duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove non-predictible features/check for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of non-plausible values:\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "columns_cause = ['prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic',\n",
    "       'prct_cause_materiel_roulant', 'prct_cause_gestion_gare',\n",
    "       'prct_cause_prise_en_charge_voyageurs']\n",
    "\n",
    "columns_retard = ['retard_moyen_depart',\n",
    "       'retard_moyen_tous_trains_depart', 'commentaire_retards_depart',\n",
    "       'nb_train_retard_arrivee','retard_moyen_tous_trains_arrivee', 'commentaires_retard_arrivee',\n",
    "       'nb_train_retard_sup_15', 'retard_moyen_trains_retard_sup15',\n",
    "       'nb_train_retard_sup_30', 'nb_train_retard_sup_60',\"nb_train_depart_retard\"]\n",
    "\n",
    "other_columns = ['nb_annulation', 'commentaire_annulation','duree_moyenne']\n",
    "\n",
    "# \"duree_moyenne\" could be a useful feature with a few feature engineering \n",
    "# (estimating the mean for every line and add the value in a new feature)\n",
    "# This could also be done with the \"retard\" features, but there are highly correlated to the target\n",
    "# Maybe this could be done for the \"cause\" features?\n",
    "\n",
    "def clean_dataset(df,other_columns,columns_retard):\n",
    "    columns_to_remove = other_columns + columns_retard\n",
    "    df = df.drop(columns_to_remove, axis=1)\n",
    "    df = df.drop([2886,2889],axis = 0)  # Remove outliers isolated in the next cell\n",
    "    df = df.reset_index(drop = True)\n",
    "    for i, d in enumerate(df[\"date\"].tolist()):  # Remove first lockdown\n",
    "        month, day, year = d.split('/')\n",
    "        if (int(year) == 2020 and int(month) in [3,4,5]):\n",
    "              df = df.drop(i,axis = 0)\n",
    "    return df\n",
    "\n",
    "def check_errors(df,columns_cause):\n",
    "    print(\"number of non-plausible values:\")\n",
    "    print(len(df[df[\"duree_moyenne\"]<0]))\n",
    "    print(len(df[df[\"nb_train_prevu\"]<0]))\n",
    "    print(len(df[df[\"retard_moyen_arrivee\"]<0]))\n",
    "    for col in columns_cause:\n",
    "       print(len(df[(df[col]<0) | (df[col]>100)]))\n",
    "\n",
    "check_errors(df,columns_cause)       \n",
    "clean_df = clean_dataset(df,other_columns,columns_retard,)  # Test\n",
    "# Dataset cleaning should be done on train and test set separately -> ensure reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>service</th>\n",
       "      <th>gare_depart</th>\n",
       "      <th>gare_arrivee</th>\n",
       "      <th>duree_moyenne</th>\n",
       "      <th>nb_train_prevu</th>\n",
       "      <th>nb_annulation</th>\n",
       "      <th>commentaire_annulation</th>\n",
       "      <th>nb_train_depart_retard</th>\n",
       "      <th>retard_moyen_depart</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_train_retard_sup_15</th>\n",
       "      <th>retard_moyen_trains_retard_sup15</th>\n",
       "      <th>nb_train_retard_sup_30</th>\n",
       "      <th>nb_train_retard_sup_60</th>\n",
       "      <th>prct_cause_externe</th>\n",
       "      <th>prct_cause_infra</th>\n",
       "      <th>prct_cause_gestion_trafic</th>\n",
       "      <th>prct_cause_materiel_roulant</th>\n",
       "      <th>prct_cause_gestion_gare</th>\n",
       "      <th>prct_cause_prise_en_charge_voyageurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>11/1/2019</td>\n",
       "      <td>National</td>\n",
       "      <td>MONTPELLIER</td>\n",
       "      <td>PARIS LYON</td>\n",
       "      <td>380</td>\n",
       "      <td>227</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189</td>\n",
       "      <td>4.910406</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>34.677381</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>52.272727</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>15.909091</td>\n",
       "      <td>15.909091</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>11/1/2019</td>\n",
       "      <td>National</td>\n",
       "      <td>NIMES</td>\n",
       "      <td>PARIS LYON</td>\n",
       "      <td>224</td>\n",
       "      <td>226</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190</td>\n",
       "      <td>8.765614</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>34.677381</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>46.774194</td>\n",
       "      <td>17.741935</td>\n",
       "      <td>14.516129</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>4.83871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   service  gare_depart gare_arrivee  duree_moyenne  \\\n",
       "2886  11/1/2019  National  MONTPELLIER   PARIS LYON            380   \n",
       "2889  11/1/2019  National        NIMES   PARIS LYON            224   \n",
       "\n",
       "      nb_train_prevu  nb_annulation  commentaire_annulation  \\\n",
       "2886             227             11                     NaN   \n",
       "2889             226             11                     NaN   \n",
       "\n",
       "      nb_train_depart_retard  retard_moyen_depart  ...  \\\n",
       "2886                     189             4.910406  ...   \n",
       "2889                     190             8.765614  ...   \n",
       "\n",
       "      nb_train_retard_sup_15  retard_moyen_trains_retard_sup15  \\\n",
       "2886                      44                         34.677381   \n",
       "2889                      44                         34.677381   \n",
       "\n",
       "      nb_train_retard_sup_30  nb_train_retard_sup_60  prct_cause_externe  \\\n",
       "2886                      18                       3           52.272727   \n",
       "2889                      18                       3           46.774194   \n",
       "\n",
       "     prct_cause_infra  prct_cause_gestion_trafic  prct_cause_materiel_roulant  \\\n",
       "2886        13.636364                  15.909091                    15.909091   \n",
       "2889        17.741935                  14.516129                    12.903226   \n",
       "\n",
       "      prct_cause_gestion_gare  prct_cause_prise_en_charge_voyageurs  \n",
       "2886                 2.272727                               0.00000  \n",
       "2889                 3.225806                               4.83871  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"retard_moyen_arrivee\"]<0] #  Something happened this month?\n",
    "\n",
    "# I dont' see any valuable reason that would explain these outlier, we can remove or impute them\n",
    "# TODO check covid period and try impute the previous outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_set(df):\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    for i, d in enumerate(df[\"date\"].tolist()):\n",
    "        month, day, year = d.split('/')\n",
    "        if int(year)<2023:\n",
    "            train_idx.append(i)\n",
    "        else:\n",
    "            test_idx.append(i)\n",
    "    \n",
    "    train_set = df.iloc[train_idx].copy(deep=True)\n",
    "    test_set = df.iloc[test_idx].copy(deep=True)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "trainset, testset = get_train_test_set(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (encoding/scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,LabelBinarizer,OrdinalEncoder,MinMaxScaler,Normalizer,RobustScaler\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "def manage_date_column(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month.apply(str).apply(lambda x:[x])\n",
    "    df = df.drop(\"date\",axis=1)\n",
    "    return df\n",
    "\n",
    "def preprocessing(df1,target,estimated_retard_moyen = False):\n",
    "    df = df1.copy()\n",
    "    df = manage_date_column(df)\n",
    "    df[\"gare_arrivee\"] = df[\"gare_arrivee\"].apply(lambda x:[x])\n",
    "    df[\"gare_depart\"] = df[\"gare_depart\"].apply(lambda x:[x])\n",
    "    \n",
    "    df[\"ligne\"] = df.apply(lambda x:x[\"gare_arrivee\"]+x[\"gare_depart\"],axis = 1)\n",
    "    df = df.drop([\"gare_arrivee\",\"gare_depart\"],axis = 1)\n",
    "    \n",
    "    scaling_cols = [\"nb_train_prevu\"]\n",
    "    hash_cols1 = \"month\"\n",
    "    hash_cols2 = [\"ligne\"]  # \"gare_depart\",\"gare_arrivee\"\n",
    "    binarizer_cols = []\n",
    "    onehot_cols = [\"service\"]\n",
    "    ordinal_encode_cols = []\n",
    "        \n",
    "    if estimated_retard_moyen:\n",
    "        scaling_cols += [\"estimated_retard_moyen\"]\n",
    "        \n",
    "    y = df[target] \n",
    "    X = df.drop(target,axis = 1)\n",
    "           \n",
    "    binarizer_transformer = Pipeline(steps=[\n",
    "        ('binarizer',LabelBinarizer())])\n",
    "    hash_transformer1 = Pipeline(steps=[\n",
    "        ('hashing', FeatureHasher(n_features=4,input_type = \"string\"))]) # For month\n",
    "    hash_transformer2 = Pipeline(steps=[\n",
    "        ('hashing2', FeatureHasher(n_features=16,input_type = \"string\"))]) # For stations\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', RobustScaler())])\n",
    "    onehot_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder())])\n",
    "    ordinal_encode_transformer = Pipeline(steps=[\n",
    "        ('ordinal_encode', OrdinalEncoder())])\n",
    "\n",
    "    transformers=[\n",
    "            # ('cat', binarizer_transformer,binarizer_cols),\n",
    "            ('hash', hash_transformer1, hash_cols1)]\n",
    "    \n",
    "    for i in range(len(hash_cols2)):\n",
    "        transformers.append(('hash'+str(i), hash_transformer2, hash_cols2[i]))\n",
    "     \n",
    "    transformers += [('num', numeric_transformer, scaling_cols),\n",
    "            ('one', onehot_transformer, onehot_cols),\n",
    "            # ('ord', ordinal_encode_transformer, ordinal_encode_cols)\n",
    "            ]\n",
    "\n",
    "    # print(transformers) \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=transformers\n",
    "        #remainder = 'passthrough', # Will cause undesirerable columns to stay in X_transformed\n",
    "        )\n",
    "    \n",
    "    X_transformed = preprocessor.fit_transform(X).todense()\n",
    "    \n",
    "    return X_transformed,y\n",
    "\n",
    "target = \"retard_moyen_arrivee\"\n",
    "# ['prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic','prct_cause_materiel_roulant', 'prct_cause_gestion_gare','prct_cause_prise_en_charge_voyageurs']\n",
    "\n",
    "X_train,y_train = preprocessing(trainset,target)\n",
    "X_test,y_test = preprocessing(testset,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.600867455016962\n",
      "345.20165594816774\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(np.asarray(X_train),np.asarray(y_train))\n",
    "y_pred = model.predict(np.asarray(X_test))\n",
    "\n",
    "print(mean_absolute_error(y_pred,y_test))\n",
    "print(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN\n",
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 1000\n",
    "\n",
    "X = np.asarray(X_train)\n",
    "y = np.asarray(y_train)\n",
    "T = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "scores_list = []\n",
    "\n",
    "for i in range(n_neighbors):\n",
    "    knn = neighbors.KNeighborsRegressor(i+1, weights='distance')\n",
    "    scores = cross_val_score(knn, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "    model_list.append(knn)\n",
    "    scores_list.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(n_neighbors=290, weights='distance') -226.04317388223672\n"
     ]
    }
   ],
   "source": [
    "best_model = model_list[0]\n",
    "best_score_mean = scores_list[0].mean()\n",
    "\n",
    "for i in range(1, len(model_list)):\n",
    "    score_mean = scores_list[i].mean()\n",
    "\n",
    "    if score_mean > best_score_mean:\n",
    "        best_score_mean = score_mean\n",
    "        best_model = model_list[i]\n",
    "\n",
    "print(best_model, best_score_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with 5 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  340.13917802800484\n",
      "MAE:  10.409088028485911\n",
      "R2:  0.04695801864961835\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X,y)\n",
    "best_model.predict(T)\n",
    "pred_knn = best_model.predict(T)\n",
    "print(\"MSE: \",mean_squared_error(y_test, pred_knn))\n",
    "print(\"MAE: \",mean_absolute_error(y_test, pred_knn))\n",
    "print(\"R2: \",r2_score(y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR\n",
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(svr, param_grid={'kernel': ['linear', 'rbf', 'poly'], 'C': [0.1, 1, 10]}, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "X = np.asarray(X_train)\n",
    "y = np.asarray(y_train)\n",
    "T = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=SVR(),\n",
       "             param_grid={'C': [0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate score\n",
    "#### Define score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_svr = SVR(kernel=best_params['kernel'], C=best_params['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate prediction and deduce score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  352.82268314889524\n",
      "MAE:  10.40045922772035\n",
      "R2:  0.01141988122904214\n"
     ]
    }
   ],
   "source": [
    "pred_svr = best_svr.predict(T)\n",
    "print(\"MSE: \",mean_squared_error(y_test, pred_svr))\n",
    "print(\"MAE: \",mean_absolute_error(y_test, pred_svr))\n",
    "print(\"R2: \",r2_score(y_test, pred_svr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging, Random Forest, Extra Trees\n",
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred), mean_absolute_error(y_true, y_pred), mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def add_value_in_dict(dict_metrics, model_name, score_metrics):\n",
    "    dict_metrics[model_name] = dict()\n",
    "    dict_metrics[model_name][\"r2_score\"] = score_metrics[0]\n",
    "    dict_metrics[model_name][\"mean_absolute_error\"] = score_metrics[1]\n",
    "    dict_metrics[model_name][\"mean_squared_error\"] = score_metrics[2]\n",
    "\n",
    "def values_from_cross_validate(model, X_train, y_train):\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5,\n",
    "                                 scoring=('r2', 'neg_mean_absolute_error', 'neg_mean_squared_error'))\n",
    "    \n",
    "    del scores['fit_time']\n",
    "    del scores['score_time']\n",
    "\n",
    "    for key, value in scores.items():\n",
    "        scores[key] = [scores[key].mean(), scores[key].std()]\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def grid_search(regressor, param_grid, X, y):\n",
    "    gs = GridSearchCV(regressor, param_grid, cv=5, scoring=['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error'], refit='neg_mean_squared_error', n_jobs=-1)\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    best_params = gs.best_params_\n",
    "    best_regressor = gs.best_estimator_\n",
    "    \n",
    "    print(\"Best Parameters: \", best_params)\n",
    "    print(\"Best Score (neg_mean_squared_error): \", gs.best_score_)\n",
    "\n",
    "    return best_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_adaboost = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "param_grid_bagging = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "}\n",
    "param_grid_extratrees = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "param_grid_gradientboosting = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "param_grid_randomforest = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dict_metrics = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'learning_rate': 0.01, 'loss': 'exponential', 'n_estimators': 50}\n",
      "Best Score (neg_mean_squared_error):  -198.13809528802622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_features': 0.5, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "Best Score (neg_mean_squared_error):  -191.3773816199562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Score (neg_mean_squared_error):  -185.40932423782485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best Score (neg_mean_squared_error):  -187.66725004138215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Best Score (neg_mean_squared_error):  -191.26520038067073\n"
     ]
    }
   ],
   "source": [
    "model_adaboost = grid_search(AdaBoostRegressor(), param_grid_adaboost, X_train, y_train)\n",
    "model_bagging = grid_search(BaggingRegressor(), param_grid_bagging, X_train, y_train)\n",
    "model_extratrees = grid_search(ExtraTreesRegressor(), param_grid_extratrees, X_train, y_train)\n",
    "model_gradientboosting = grid_search(GradientBoostingRegressor(), param_grid_gradientboosting, X_train, y_train)\n",
    "model_randomforest = grid_search(RandomForestRegressor(), param_grid_randomforest, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "add_value_in_dict(dict_metrics, \"adaboost\", calculate_metrics(y_test, model_adaboost.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics, \"bagging\", calculate_metrics(y_test, model_bagging.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics, \"extratrees\", calculate_metrics(y_test, model_extratrees.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics, \"gradientboosting\", calculate_metrics(y_test, model_gradientboosting.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics, \"randomforest\", calculate_metrics(y_test, model_randomforest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adaboost': {'r2_score': 0.0328915073316971,\n",
       "  'mean_absolute_error': 10.517961818278103,\n",
       "  'mean_squared_error': 345.15949370247284},\n",
       " 'bagging': {'r2_score': 0.05260202472105713,\n",
       "  'mean_absolute_error': 10.314110416973085,\n",
       "  'mean_squared_error': 338.12484117454943},\n",
       " 'extratrees': {'r2_score': 0.0657835709648017,\n",
       "  'mean_absolute_error': 10.061719654838843,\n",
       "  'mean_squared_error': 333.42036813745136},\n",
       " 'gradientboosting': {'r2_score': 0.06532150483035293,\n",
       "  'mean_absolute_error': 10.041153296806657,\n",
       "  'mean_squared_error': 333.5852788111063},\n",
       " 'randomforest': {'r2_score': 0.06375881264350991,\n",
       "  'mean_absolute_error': 10.153608757078258,\n",
       "  'mean_squared_error': 334.14300118466895}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prend le modèle adaboost qui donne le meilleur MSE<br>\n",
    "On rajoute les valeurs prédites au testset pour prédire les causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "testset[\"retard_moyen_arrivee\"] = model_adaboost.predict(X_test)\n",
    "trainset.rename(columns={\"retard_moyen_arrivee\": \"estimated_retard_moyen\"}, inplace=True)\n",
    "testset.rename(columns={\"retard_moyen_arrivee\": \"estimated_retard_moyen\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>service</th>\n",
       "      <th>gare_depart</th>\n",
       "      <th>gare_arrivee</th>\n",
       "      <th>nb_train_prevu</th>\n",
       "      <th>estimated_retard_moyen</th>\n",
       "      <th>prct_cause_externe</th>\n",
       "      <th>prct_cause_infra</th>\n",
       "      <th>prct_cause_gestion_trafic</th>\n",
       "      <th>prct_cause_materiel_roulant</th>\n",
       "      <th>prct_cause_gestion_gare</th>\n",
       "      <th>prct_cause_prise_en_charge_voyageurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>International</td>\n",
       "      <td>PARIS EST</td>\n",
       "      <td>STUTTGART</td>\n",
       "      <td>150</td>\n",
       "      <td>31.448081</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>34.375000</td>\n",
       "      <td>21.875000</td>\n",
       "      <td>21.875000</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>International</td>\n",
       "      <td>PARIS LYON</td>\n",
       "      <td>ZURICH</td>\n",
       "      <td>129</td>\n",
       "      <td>38.459434</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7428</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>National</td>\n",
       "      <td>BORDEAUX ST JEAN</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>1075</td>\n",
       "      <td>27.483933</td>\n",
       "      <td>26.811594</td>\n",
       "      <td>27.536232</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>11.594203</td>\n",
       "      <td>5.072464</td>\n",
       "      <td>12.318841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7429</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>National</td>\n",
       "      <td>CHAMBERY CHALLES LES EAUX</td>\n",
       "      <td>PARIS LYON</td>\n",
       "      <td>334</td>\n",
       "      <td>38.459434</td>\n",
       "      <td>23.943662</td>\n",
       "      <td>29.577465</td>\n",
       "      <td>36.619718</td>\n",
       "      <td>2.816901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.042254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7430</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>National</td>\n",
       "      <td>MACON LOCHE</td>\n",
       "      <td>PARIS LYON</td>\n",
       "      <td>252</td>\n",
       "      <td>38.459434</td>\n",
       "      <td>17.391304</td>\n",
       "      <td>24.637681</td>\n",
       "      <td>42.028986</td>\n",
       "      <td>5.797101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.144928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>6/1/2023</td>\n",
       "      <td>National</td>\n",
       "      <td>STRASBOURG</td>\n",
       "      <td>PARIS EST</td>\n",
       "      <td>492</td>\n",
       "      <td>30.987977</td>\n",
       "      <td>7.619048</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>55.238095</td>\n",
       "      <td>18.095238</td>\n",
       "      <td>7.619048</td>\n",
       "      <td>5.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>6/1/2023</td>\n",
       "      <td>National</td>\n",
       "      <td>TOULOUSE MATABIAU</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>215</td>\n",
       "      <td>34.357469</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>19.444444</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8149</th>\n",
       "      <td>6/1/2023</td>\n",
       "      <td>National</td>\n",
       "      <td>TOURS</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>192</td>\n",
       "      <td>27.739120</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>10.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8150</th>\n",
       "      <td>6/1/2023</td>\n",
       "      <td>National</td>\n",
       "      <td>VALENCE ALIXAN TGV</td>\n",
       "      <td>PARIS LYON</td>\n",
       "      <td>440</td>\n",
       "      <td>38.459434</td>\n",
       "      <td>26.724138</td>\n",
       "      <td>19.827586</td>\n",
       "      <td>27.586207</td>\n",
       "      <td>7.758621</td>\n",
       "      <td>7.758621</td>\n",
       "      <td>10.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8151</th>\n",
       "      <td>6/1/2023</td>\n",
       "      <td>National</td>\n",
       "      <td>VANNES</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>284</td>\n",
       "      <td>32.804081</td>\n",
       "      <td>11.627907</td>\n",
       "      <td>39.534884</td>\n",
       "      <td>11.627907</td>\n",
       "      <td>18.604651</td>\n",
       "      <td>11.627907</td>\n",
       "      <td>6.976744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>726 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date        service                gare_depart        gare_arrivee  \\\n",
       "7426  1/1/2023  International                  PARIS EST           STUTTGART   \n",
       "7427  1/1/2023  International                 PARIS LYON              ZURICH   \n",
       "7428  1/1/2023       National           BORDEAUX ST JEAN  PARIS MONTPARNASSE   \n",
       "7429  1/1/2023       National  CHAMBERY CHALLES LES EAUX          PARIS LYON   \n",
       "7430  1/1/2023       National                MACON LOCHE          PARIS LYON   \n",
       "...        ...            ...                        ...                 ...   \n",
       "8147  6/1/2023       National                 STRASBOURG           PARIS EST   \n",
       "8148  6/1/2023       National          TOULOUSE MATABIAU  PARIS MONTPARNASSE   \n",
       "8149  6/1/2023       National                      TOURS  PARIS MONTPARNASSE   \n",
       "8150  6/1/2023       National         VALENCE ALIXAN TGV          PARIS LYON   \n",
       "8151  6/1/2023       National                     VANNES  PARIS MONTPARNASSE   \n",
       "\n",
       "      nb_train_prevu  estimated_retard_moyen  prct_cause_externe  \\\n",
       "7426             150               31.448081            6.250000   \n",
       "7427             129               38.459434           15.000000   \n",
       "7428            1075               27.483933           26.811594   \n",
       "7429             334               38.459434           23.943662   \n",
       "7430             252               38.459434           17.391304   \n",
       "...              ...                     ...                 ...   \n",
       "8147             492               30.987977            7.619048   \n",
       "8148             215               34.357469           13.888889   \n",
       "8149             192               27.739120           14.285714   \n",
       "8150             440               38.459434           26.724138   \n",
       "8151             284               32.804081           11.627907   \n",
       "\n",
       "      prct_cause_infra  prct_cause_gestion_trafic  \\\n",
       "7426          3.125000                  34.375000   \n",
       "7427         15.000000                  35.000000   \n",
       "7428         27.536232                  16.666667   \n",
       "7429         29.577465                  36.619718   \n",
       "7430         24.637681                  42.028986   \n",
       "...                ...                        ...   \n",
       "8147          5.714286                  55.238095   \n",
       "8148         33.333333                   8.333333   \n",
       "8149         21.428571                  28.571429   \n",
       "8150         19.827586                  27.586207   \n",
       "8151         39.534884                  11.627907   \n",
       "\n",
       "      prct_cause_materiel_roulant  prct_cause_gestion_gare  \\\n",
       "7426                    21.875000                21.875000   \n",
       "7427                    15.000000                 5.000000   \n",
       "7428                    11.594203                 5.072464   \n",
       "7429                     2.816901                 0.000000   \n",
       "7430                     5.797101                 0.000000   \n",
       "...                           ...                      ...   \n",
       "8147                    18.095238                 7.619048   \n",
       "8148                    19.444444                 8.333333   \n",
       "8149                    21.428571                 3.571429   \n",
       "8150                     7.758621                 7.758621   \n",
       "8151                    18.604651                11.627907   \n",
       "\n",
       "      prct_cause_prise_en_charge_voyageurs  \n",
       "7426                             12.500000  \n",
       "7427                             15.000000  \n",
       "7428                             12.318841  \n",
       "7429                              7.042254  \n",
       "7430                             10.144928  \n",
       "...                                    ...  \n",
       "8147                              5.714286  \n",
       "8148                             16.666667  \n",
       "8149                             10.714286  \n",
       "8150                             10.344828  \n",
       "8151                              6.976744  \n",
       "\n",
       "[726 rows x 12 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic','prct_cause_materiel_roulant', 'prct_cause_gestion_gare','prct_cause_prise_en_charge_voyageurs']\n",
    "\n",
    "X_train,y_train = preprocessing(trainset,target,estimated_retard_moyen=True)\n",
    "X_test,y_test = preprocessing(testset,target,estimated_retard_moyen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut prédire 6 valeurs (les valeurs de probabilité des causes de retard), cependant nous ne pouvons pas utiliser les régresseurs AdaBoost et GradientBoosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metrics_cause = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_features': 0.5, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "Best Score (neg_mean_squared_error):  -174.64071509443676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Score (neg_mean_squared_error):  -173.81416545860094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best Score (neg_mean_squared_error):  -174.85864480093005\n"
     ]
    }
   ],
   "source": [
    "model_cause_bagging = grid_search(BaggingRegressor(), param_grid_bagging, X_train, y_train)\n",
    "model_cause_extratrees = grid_search(ExtraTreesRegressor(), param_grid_extratrees, X_train, y_train)\n",
    "model_cause_randomforest = grid_search(RandomForestRegressor(), param_grid_randomforest, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\Users\\matth\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "add_value_in_dict(dict_metrics_cause, \"bagging\", calculate_metrics(y_test, model_cause_bagging.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics_cause, \"extratrees\", calculate_metrics(y_test, model_cause_extratrees.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics_cause, \"randomforest\", calculate_metrics(y_test, model_cause_randomforest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging': {'r2_score': -0.013659792648185934,\n",
       "  'mean_absolute_error': 8.937787399905917,\n",
       "  'mean_squared_error': 148.2577293229293},\n",
       " 'extratrees': {'r2_score': 0.04000825945446127,\n",
       "  'mean_absolute_error': 8.656157436636063,\n",
       "  'mean_squared_error': 139.7035674434797},\n",
       " 'randomforest': {'r2_score': 0.008658729290887623,\n",
       "  'mean_absolute_error': 8.859132489640537,\n",
       "  'mean_squared_error': 144.7905826982563}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_metrics_cause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle donnant les meilleurs résultats est celui de l'ExtraTrees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

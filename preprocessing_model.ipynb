{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"regularite-mensuelle-tgv-aqst.csv\",encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'service', 'gare_depart', 'gare_arrivee', 'duree_moyenne',\n",
       "       'nb_train_prevu', 'nb_annulation', 'commentaire_annulation',\n",
       "       'nb_train_depart_retard', 'retard_moyen_depart',\n",
       "       'retard_moyen_tous_trains_depart', 'commentaire_retards_depart',\n",
       "       'nb_train_retard_arrivee', 'retard_moyen_arrivee',\n",
       "       'retard_moyen_tous_trains_arrivee', 'commentaires_retard_arrivee',\n",
       "       'nb_train_retard_sup_15', 'retard_moyen_trains_retard_sup15',\n",
       "       'nb_train_retard_sup_30', 'nb_train_retard_sup_60',\n",
       "       'prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic',\n",
       "       'prct_cause_materiel_roulant', 'prct_cause_gestion_gare',\n",
       "       'prct_cause_prise_en_charge_voyageurs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>service</th>\n",
       "      <th>gare_depart</th>\n",
       "      <th>gare_arrivee</th>\n",
       "      <th>duree_moyenne</th>\n",
       "      <th>nb_train_prevu</th>\n",
       "      <th>nb_annulation</th>\n",
       "      <th>commentaire_annulation</th>\n",
       "      <th>nb_train_depart_retard</th>\n",
       "      <th>retard_moyen_depart</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_train_retard_sup_15</th>\n",
       "      <th>retard_moyen_trains_retard_sup15</th>\n",
       "      <th>nb_train_retard_sup_30</th>\n",
       "      <th>nb_train_retard_sup_60</th>\n",
       "      <th>prct_cause_externe</th>\n",
       "      <th>prct_cause_infra</th>\n",
       "      <th>prct_cause_gestion_trafic</th>\n",
       "      <th>prct_cause_materiel_roulant</th>\n",
       "      <th>prct_cause_gestion_gare</th>\n",
       "      <th>prct_cause_prise_en_charge_voyageurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>BORDEAUX ST JEAN</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>141</td>\n",
       "      <td>870</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>289</td>\n",
       "      <td>11.247809</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>6.511118</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>36.134454</td>\n",
       "      <td>31.092437</td>\n",
       "      <td>10.924370</td>\n",
       "      <td>15.966387</td>\n",
       "      <td>5.042017</td>\n",
       "      <td>0.840336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>LA ROCHELLE VILLE</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>165</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>5.696096</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>QUIMPER</td>\n",
       "      <td>220</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "      <td>9.501351</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>7.548387</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>26.923077</td>\n",
       "      <td>38.461538</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>ST MALO</td>\n",
       "      <td>156</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>19.912500</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>6.724757</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2018</td>\n",
       "      <td>National</td>\n",
       "      <td>PARIS MONTPARNASSE</td>\n",
       "      <td>ST PIERRE DES CORPS</td>\n",
       "      <td>61</td>\n",
       "      <td>391</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>7.796995</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>3.346487</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>21.212121</td>\n",
       "      <td>42.424242</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>21.212121</td>\n",
       "      <td>6.060606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   service         gare_depart         gare_arrivee  duree_moyenne  \\\n",
       "0  1/1/2018  National    BORDEAUX ST JEAN   PARIS MONTPARNASSE            141   \n",
       "1  1/1/2018  National   LA ROCHELLE VILLE   PARIS MONTPARNASSE            165   \n",
       "2  1/1/2018  National  PARIS MONTPARNASSE              QUIMPER            220   \n",
       "3  1/1/2018  National  PARIS MONTPARNASSE              ST MALO            156   \n",
       "4  1/1/2018  National  PARIS MONTPARNASSE  ST PIERRE DES CORPS             61   \n",
       "\n",
       "   nb_train_prevu  nb_annulation  commentaire_annulation  \\\n",
       "0             870              5                     NaN   \n",
       "1             222              0                     NaN   \n",
       "2             248              1                     NaN   \n",
       "3             102              0                     NaN   \n",
       "4             391              2                     NaN   \n",
       "\n",
       "   nb_train_depart_retard  retard_moyen_depart  ...  nb_train_retard_sup_15  \\\n",
       "0                     289            11.247809  ...                     110   \n",
       "1                       8             2.875000  ...                      22   \n",
       "2                      37             9.501351  ...                      26   \n",
       "3                      12            19.912500  ...                       8   \n",
       "4                      61             7.796995  ...                      17   \n",
       "\n",
       "   retard_moyen_trains_retard_sup15  nb_train_retard_sup_30  \\\n",
       "0                          6.511118                      44   \n",
       "1                          5.696096                       5   \n",
       "2                          7.548387                      17   \n",
       "3                          6.724757                       6   \n",
       "4                          3.346487                       6   \n",
       "\n",
       "   nb_train_retard_sup_60  prct_cause_externe prct_cause_infra  \\\n",
       "0                       8           36.134454        31.092437   \n",
       "1                       0           15.384615        30.769231   \n",
       "2                       7           26.923077        38.461538   \n",
       "3                       4           23.076923        46.153846   \n",
       "4                       0           21.212121        42.424242   \n",
       "\n",
       "   prct_cause_gestion_trafic  prct_cause_materiel_roulant  \\\n",
       "0                  10.924370                    15.966387   \n",
       "1                  38.461538                    11.538462   \n",
       "2                  15.384615                    19.230769   \n",
       "3                   7.692308                    15.384615   \n",
       "4                   9.090909                    21.212121   \n",
       "\n",
       "   prct_cause_gestion_gare  prct_cause_prise_en_charge_voyageurs  \n",
       "0                 5.042017                              0.840336  \n",
       "1                 3.846154                              0.000000  \n",
       "2                 0.000000                              0.000000  \n",
       "3                 7.692308                              0.000000  \n",
       "4                 6.060606                              0.000000  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                    0.000000\n",
       "prct_cause_materiel_roulant             0.000000\n",
       "prct_cause_gestion_trafic               0.000000\n",
       "prct_cause_infra                        0.000000\n",
       "prct_cause_externe                      0.000000\n",
       "nb_train_retard_sup_60                  0.000000\n",
       "nb_train_retard_sup_30                  0.000000\n",
       "retard_moyen_trains_retard_sup15        0.000000\n",
       "nb_train_retard_sup_15                  0.000000\n",
       "retard_moyen_tous_trains_arrivee        0.000000\n",
       "retard_moyen_arrivee                    0.000000\n",
       "prct_cause_gestion_gare                 0.000000\n",
       "nb_train_retard_arrivee                 0.000000\n",
       "retard_moyen_tous_trains_depart         0.000000\n",
       "retard_moyen_depart                     0.000000\n",
       "nb_train_depart_retard                  0.000000\n",
       "nb_annulation                           0.000000\n",
       "nb_train_prevu                          0.000000\n",
       "duree_moyenne                           0.000000\n",
       "gare_arrivee                            0.000000\n",
       "gare_depart                             0.000000\n",
       "service                                 0.000000\n",
       "prct_cause_prise_en_charge_voyageurs    0.000000\n",
       "commentaires_retard_arrivee             0.914398\n",
       "commentaire_annulation                  1.000000\n",
       "commentaire_retards_depart              1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isna().sum()/df.shape[0]).sort_values(ascending=True)  # Nan only in the comment columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>service</th>\n",
       "      <th>gare_depart</th>\n",
       "      <th>gare_arrivee</th>\n",
       "      <th>duree_moyenne</th>\n",
       "      <th>nb_train_prevu</th>\n",
       "      <th>nb_annulation</th>\n",
       "      <th>commentaire_annulation</th>\n",
       "      <th>nb_train_depart_retard</th>\n",
       "      <th>retard_moyen_depart</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_train_retard_sup_15</th>\n",
       "      <th>retard_moyen_trains_retard_sup15</th>\n",
       "      <th>nb_train_retard_sup_30</th>\n",
       "      <th>nb_train_retard_sup_60</th>\n",
       "      <th>prct_cause_externe</th>\n",
       "      <th>prct_cause_infra</th>\n",
       "      <th>prct_cause_gestion_trafic</th>\n",
       "      <th>prct_cause_materiel_roulant</th>\n",
       "      <th>prct_cause_gestion_gare</th>\n",
       "      <th>prct_cause_prise_en_charge_voyageurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, service, gare_depart, gare_arrivee, duree_moyenne, nb_train_prevu, nb_annulation, commentaire_annulation, nb_train_depart_retard, retard_moyen_depart, retard_moyen_tous_trains_depart, commentaire_retards_depart, nb_train_retard_arrivee, retard_moyen_arrivee, retard_moyen_tous_trains_arrivee, commentaires_retard_arrivee, nb_train_retard_sup_15, retard_moyen_trains_retard_sup15, nb_train_retard_sup_30, nb_train_retard_sup_60, prct_cause_externe, prct_cause_infra, prct_cause_gestion_trafic, prct_cause_materiel_roulant, prct_cause_gestion_gare, prct_cause_prise_en_charge_voyageurs]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]  # No duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove non-predictible features/check for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of non-plausible values:\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "columns_cause = ['prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic',\n",
    "       'prct_cause_materiel_roulant', 'prct_cause_gestion_gare',\n",
    "       'prct_cause_prise_en_charge_voyageurs']\n",
    "\n",
    "columns_retard = ['retard_moyen_depart',\n",
    "       'retard_moyen_tous_trains_depart', 'commentaire_retards_depart',\n",
    "       'nb_train_retard_arrivee','retard_moyen_tous_trains_arrivee', 'commentaires_retard_arrivee',\n",
    "       'nb_train_retard_sup_15', 'retard_moyen_trains_retard_sup15',\n",
    "       'nb_train_retard_sup_30', 'nb_train_retard_sup_60',\"nb_train_depart_retard\"]\n",
    "\n",
    "other_columns = ['nb_annulation', 'commentaire_annulation','duree_moyenne']\n",
    "\n",
    "# \"duree_moyenne\" could be a useful feature with a few feature engineering \n",
    "# (estimating the mean for every line and add the value in a new feature)\n",
    "# This could also be done with the \"retard\" features, but there are highly correlated to the target\n",
    "# Maybe this could be done for the \"cause\" features?\n",
    "\n",
    "def clean_dataset(df,other_columns,columns_retard):\n",
    "    columns_to_remove = other_columns + columns_retard\n",
    "    df = df.drop(columns_to_remove, axis=1)\n",
    "    df = df.drop([2886,2889],axis = 0)  # Remove outliers isolated in the next cell\n",
    "    df = df.reset_index(drop = True)\n",
    "    for i, d in enumerate(df[\"date\"].tolist()):  # Remove first lockdown\n",
    "        month, day, year = d.split('/')\n",
    "        if (int(year) == 2020 and int(month) in [3,4,5]):\n",
    "              df = df.drop(i,axis = 0)\n",
    "    return df\n",
    "\n",
    "def check_errors(df,columns_cause):\n",
    "    print(\"number of non-plausible values:\")\n",
    "    print(len(df[df[\"duree_moyenne\"]<0]))\n",
    "    print(len(df[df[\"nb_train_prevu\"]<0]))\n",
    "    print(len(df[df[\"retard_moyen_arrivee\"]<0]))\n",
    "    for col in columns_cause:\n",
    "       print(len(df[(df[col]<0) | (df[col]>100)]))\n",
    "\n",
    "check_errors(df,columns_cause)       \n",
    "clean_df = clean_dataset(df,other_columns,columns_retard,)  # Test\n",
    "# Dataset cleaning should be done on train and test set separately -> ensure reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>service</th>\n",
       "      <th>gare_depart</th>\n",
       "      <th>gare_arrivee</th>\n",
       "      <th>duree_moyenne</th>\n",
       "      <th>nb_train_prevu</th>\n",
       "      <th>nb_annulation</th>\n",
       "      <th>commentaire_annulation</th>\n",
       "      <th>nb_train_depart_retard</th>\n",
       "      <th>retard_moyen_depart</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_train_retard_sup_15</th>\n",
       "      <th>retard_moyen_trains_retard_sup15</th>\n",
       "      <th>nb_train_retard_sup_30</th>\n",
       "      <th>nb_train_retard_sup_60</th>\n",
       "      <th>prct_cause_externe</th>\n",
       "      <th>prct_cause_infra</th>\n",
       "      <th>prct_cause_gestion_trafic</th>\n",
       "      <th>prct_cause_materiel_roulant</th>\n",
       "      <th>prct_cause_gestion_gare</th>\n",
       "      <th>prct_cause_prise_en_charge_voyageurs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>11/1/2019</td>\n",
       "      <td>National</td>\n",
       "      <td>MONTPELLIER</td>\n",
       "      <td>PARIS LYON</td>\n",
       "      <td>380</td>\n",
       "      <td>227</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189</td>\n",
       "      <td>4.910406</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>34.677381</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>52.272727</td>\n",
       "      <td>13.636364</td>\n",
       "      <td>15.909091</td>\n",
       "      <td>15.909091</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>11/1/2019</td>\n",
       "      <td>National</td>\n",
       "      <td>NIMES</td>\n",
       "      <td>PARIS LYON</td>\n",
       "      <td>224</td>\n",
       "      <td>226</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190</td>\n",
       "      <td>8.765614</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>34.677381</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>46.774194</td>\n",
       "      <td>17.741935</td>\n",
       "      <td>14.516129</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>4.83871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   service  gare_depart gare_arrivee  duree_moyenne  \\\n",
       "2886  11/1/2019  National  MONTPELLIER   PARIS LYON            380   \n",
       "2889  11/1/2019  National        NIMES   PARIS LYON            224   \n",
       "\n",
       "      nb_train_prevu  nb_annulation  commentaire_annulation  \\\n",
       "2886             227             11                     NaN   \n",
       "2889             226             11                     NaN   \n",
       "\n",
       "      nb_train_depart_retard  retard_moyen_depart  ...  \\\n",
       "2886                     189             4.910406  ...   \n",
       "2889                     190             8.765614  ...   \n",
       "\n",
       "      nb_train_retard_sup_15  retard_moyen_trains_retard_sup15  \\\n",
       "2886                      44                         34.677381   \n",
       "2889                      44                         34.677381   \n",
       "\n",
       "      nb_train_retard_sup_30  nb_train_retard_sup_60  prct_cause_externe  \\\n",
       "2886                      18                       3           52.272727   \n",
       "2889                      18                       3           46.774194   \n",
       "\n",
       "     prct_cause_infra  prct_cause_gestion_trafic  prct_cause_materiel_roulant  \\\n",
       "2886        13.636364                  15.909091                    15.909091   \n",
       "2889        17.741935                  14.516129                    12.903226   \n",
       "\n",
       "      prct_cause_gestion_gare  prct_cause_prise_en_charge_voyageurs  \n",
       "2886                 2.272727                               0.00000  \n",
       "2889                 3.225806                               4.83871  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"retard_moyen_arrivee\"]<0] #  Something happened this month?\n",
    "\n",
    "# I dont' see any valuable reason that would explain these outlier, we can remove or impute them\n",
    "# TODO check covid period and try impute the previous outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_set(df):\n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    for i, d in enumerate(df[\"date\"].tolist()):\n",
    "        month, day, year = d.split('/')\n",
    "        if int(year)<2023:\n",
    "            train_idx.append(i)\n",
    "        else:\n",
    "            test_idx.append(i)\n",
    "    \n",
    "    train_set = df.iloc[train_idx].copy(deep=True)\n",
    "    test_set = df.iloc[test_idx].copy(deep=True)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "trainset, testset = get_train_test_set(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (encoding/scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,LabelBinarizer,OrdinalEncoder,MinMaxScaler,Normalizer,RobustScaler\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "def manage_date_column(df):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month.apply(str).apply(lambda x:[x])\n",
    "    df = df.drop(\"date\",axis=1)\n",
    "    return df\n",
    "\n",
    "def preprocessing(df1,target,estimated_retard_moyen = False):\n",
    "    df = df1.copy()\n",
    "    df = manage_date_column(df)\n",
    "    df[\"gare_arrivee\"] = df[\"gare_arrivee\"].apply(lambda x:[x])\n",
    "    df[\"gare_depart\"] = df[\"gare_depart\"].apply(lambda x:[x])\n",
    "    \n",
    "    df[\"ligne\"] = df.apply(lambda x:x[\"gare_arrivee\"]+x[\"gare_depart\"],axis = 1)\n",
    "    df = df.drop([\"gare_arrivee\",\"gare_depart\"],axis = 1)\n",
    "    \n",
    "    scaling_cols = [\"nb_train_prevu\"]\n",
    "    hash_cols1 = \"month\"\n",
    "    hash_cols2 = [\"ligne\"]  # \"gare_depart\",\"gare_arrivee\"\n",
    "    binarizer_cols = []\n",
    "    onehot_cols = [\"service\"]\n",
    "    ordinal_encode_cols = []\n",
    "        \n",
    "    if estimated_retard_moyen:\n",
    "        scaling_cols += [\"estimated_retard_moyen\"]\n",
    "        \n",
    "    y = df[target] \n",
    "    X = df.drop(target,axis = 1)\n",
    "           \n",
    "    binarizer_transformer = Pipeline(steps=[\n",
    "        ('binarizer',LabelBinarizer())])\n",
    "    hash_transformer1 = Pipeline(steps=[\n",
    "        ('hashing', FeatureHasher(n_features=4,input_type = \"string\"))]) # For month\n",
    "    hash_transformer2 = Pipeline(steps=[\n",
    "        ('hashing2', FeatureHasher(n_features=16,input_type = \"string\"))]) # For stations\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', RobustScaler())])\n",
    "    onehot_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder())])\n",
    "    ordinal_encode_transformer = Pipeline(steps=[\n",
    "        ('ordinal_encode', OrdinalEncoder())])\n",
    "\n",
    "    transformers=[\n",
    "            # ('cat', binarizer_transformer,binarizer_cols),\n",
    "            ('hash', hash_transformer1, hash_cols1)]\n",
    "    \n",
    "    for i in range(len(hash_cols2)):\n",
    "        transformers.append(('hash'+str(i), hash_transformer2, hash_cols2[i]))\n",
    "     \n",
    "    transformers += [('num', numeric_transformer, scaling_cols),\n",
    "            ('one', onehot_transformer, onehot_cols),\n",
    "            # ('ord', ordinal_encode_transformer, ordinal_encode_cols)\n",
    "            ]\n",
    "\n",
    "    # print(transformers) \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=transformers\n",
    "        #remainder = 'passthrough', # Will cause undesirerable columns to stay in X_transformed\n",
    "        )\n",
    "    \n",
    "    X_transformed = preprocessor.fit_transform(X).todense()\n",
    "    \n",
    "    return X_transformed,y\n",
    "\n",
    "target = \"retard_moyen_arrivee\"\n",
    "# ['prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic','prct_cause_materiel_roulant', 'prct_cause_gestion_gare','prct_cause_prise_en_charge_voyageurs']\n",
    "\n",
    "X_train,y_train = preprocessing(trainset,target)\n",
    "X_test,y_test = preprocessing(testset,target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.599525212681877\n",
      "344.86181340300067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(np.asarray(X_train),np.asarray(y_train))\n",
    "y_pred = model.predict(np.asarray(X_test))\n",
    "\n",
    "print(mean_absolute_error(y_pred,y_test))\n",
    "print(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score, cross_validate\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN\n",
    "### Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 1000\n",
    "\n",
    "X = np.asarray(X_train)\n",
    "y = np.asarray(y_train)\n",
    "T = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/maxime/Documents/CS-5A/ApprAuto/TGV-delay-predictions/preprocessing_model.ipynb Cell 23\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxime/Documents/CS-5A/ApprAuto/TGV-delay-predictions/preprocessing_model.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_neighbors):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxime/Documents/CS-5A/ApprAuto/TGV-delay-predictions/preprocessing_model.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     knn \u001b[39m=\u001b[39m neighbors\u001b[39m.\u001b[39mKNeighborsRegressor(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/maxime/Documents/CS-5A/ApprAuto/TGV-delay-predictions/preprocessing_model.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     scores \u001b[39m=\u001b[39m cross_val_score(knn, X, y, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mneg_mean_squared_error\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxime/Documents/CS-5A/ApprAuto/TGV-delay-predictions/preprocessing_model.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model_list\u001b[39m.\u001b[39mappend(knn)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxime/Documents/CS-5A/ApprAuto/TGV-delay-predictions/preprocessing_model.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     scores_list\u001b[39m.\u001b[39mappend(scores)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:751\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    748\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    750\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[0;32m--> 751\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[1;32m    752\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[1;32m    753\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:810\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    808\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[1;32m    809\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[1;32m    811\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    814\u001b[0m         \u001b[39m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:136\u001b[0m, in \u001b[0;36m_MultimetricScorer.__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(scorer, _BaseScorer):\n\u001b[0;32m--> 136\u001b[0m         score \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39;49m_score(\n\u001b[1;32m    137\u001b[0m             cached_call, estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrouted_params\u001b[39m.\u001b[39;49mget(name)\u001b[39m.\u001b[39;49mscore\n\u001b[1;32m    138\u001b[0m         )\n\u001b[1;32m    139\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         score \u001b[39m=\u001b[39m scorer(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrouted_params\u001b[39m.\u001b[39mget(name)\u001b[39m.\u001b[39mscore)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_overlap(\n\u001b[1;32m    346\u001b[0m     message\u001b[39m=\u001b[39m(\n\u001b[1;32m    347\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m    352\u001b[0m )\n\u001b[0;32m--> 353\u001b[0m y_pred \u001b[39m=\u001b[39m method_caller(estimator, \u001b[39m\"\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m\"\u001b[39;49m, X)\n\u001b[1;32m    354\u001b[0m scoring_kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m    355\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sign \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_score_func(y_true, y_pred, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m response_method \u001b[39min\u001b[39;00m cache:\n\u001b[1;32m     84\u001b[0m     \u001b[39mreturn\u001b[39;00m cache[response_method]\n\u001b[0;32m---> 86\u001b[0m result, _ \u001b[39m=\u001b[39m _get_response_values(\n\u001b[1;32m     87\u001b[0m     estimator, \u001b[39m*\u001b[39;49margs, response_method\u001b[39m=\u001b[39;49mresponse_method, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     cache[response_method] \u001b[39m=\u001b[39m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_response.py:218\u001b[0m, in \u001b[0;36m_get_response_values\u001b[0;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m response_method \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    212\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    213\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m should either be a classifier to be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mused with response_method=\u001b[39m\u001b[39m{\u001b[39;00mresponse_method\u001b[39m}\u001b[39;00m\u001b[39m or the response_method \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mshould be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Got a regressor with response_method=\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse_method\u001b[39m}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         )\n\u001b[0;32m--> 218\u001b[0m     y_pred, pos_label \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mpredict(X), \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m y_pred, pos_label\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_regression.py:240\u001b[0m, in \u001b[0;36mKNeighborsRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    238\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     neigh_dist, neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X)\n\u001b[1;32m    242\u001b[0m weights \u001b[39m=\u001b[39m _get_weights(neigh_dist, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\n\u001b[1;32m    244\u001b[0m _y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_base.py:822\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    815\u001b[0m use_pairwise_distances_reductions \u001b[39m=\u001b[39m (\n\u001b[1;32m    816\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m     \u001b[39mand\u001b[39;00m ArgKmin\u001b[39m.\u001b[39mis_usable_for(\n\u001b[1;32m    818\u001b[0m         X \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_\n\u001b[1;32m    819\u001b[0m     )\n\u001b[1;32m    820\u001b[0m )\n\u001b[1;32m    821\u001b[0m \u001b[39mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 822\u001b[0m     results \u001b[39m=\u001b[39m ArgKmin\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m    823\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    824\u001b[0m         Y\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[1;32m    825\u001b[0m         k\u001b[39m=\u001b[39;49mn_neighbors,\n\u001b[1;32m    826\u001b[0m         metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[1;32m    827\u001b[0m         metric_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_params_,\n\u001b[1;32m    828\u001b[0m         strategy\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    829\u001b[0m         return_distance\u001b[39m=\u001b[39;49mreturn_distance,\n\u001b[1;32m    830\u001b[0m     )\n\u001b[1;32m    832\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m    833\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m issparse(X)\n\u001b[1;32m    834\u001b[0m ):\n\u001b[1;32m    835\u001b[0m     results \u001b[39m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    836\u001b[0m         X, n_neighbors\u001b[39m=\u001b[39mn_neighbors, return_distance\u001b[39m=\u001b[39mreturn_distance\n\u001b[1;32m    837\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:259\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[1;32m    180\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mreturns.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64:\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mreturn\u001b[39;00m ArgKmin64\u001b[39m.\u001b[39;49mcompute(\n\u001b[1;32m    260\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    261\u001b[0m         Y\u001b[39m=\u001b[39;49mY,\n\u001b[1;32m    262\u001b[0m         k\u001b[39m=\u001b[39;49mk,\n\u001b[1;32m    263\u001b[0m         metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    264\u001b[0m         chunk_size\u001b[39m=\u001b[39;49mchunk_size,\n\u001b[1;32m    265\u001b[0m         metric_kwargs\u001b[39m=\u001b[39;49mmetric_kwargs,\n\u001b[1;32m    266\u001b[0m         strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    267\u001b[0m         return_distance\u001b[39m=\u001b[39;49mreturn_distance,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m Y\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat32:\n\u001b[1;32m    271\u001b[0m     \u001b[39mreturn\u001b[39;00m ArgKmin32\u001b[39m.\u001b[39mcompute(\n\u001b[1;32m    272\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    273\u001b[0m         Y\u001b[39m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         return_distance\u001b[39m=\u001b[39mreturn_distance,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:90\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/threadpoolctl.py:440\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[0;32m--> 440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mtype\u001b[39m, value, traceback):\n\u001b[1;32m    441\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestore_original_limits()\n\u001b[1;32m    443\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39mcls\u001b[39m, controller, \u001b[39m*\u001b[39m, limits\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_api\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "scores_list = []\n",
    "\n",
    "for i in range(n_neighbors):\n",
    "    knn = neighbors.KNeighborsRegressor(i+1, weights='distance')\n",
    "    scores = cross_val_score(knn, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "    model_list.append(knn)\n",
    "    scores_list.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_list[0]\n",
    "best_score_mean = scores_list[0].mean()\n",
    "\n",
    "for i in range(1, len(model_list)):\n",
    "    score_mean = scores_list[i].mean()\n",
    "\n",
    "    if score_mean > best_score_mean:\n",
    "        best_score_mean = score_mean\n",
    "        best_model = model_list[i]\n",
    "\n",
    "print(best_model, best_score_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with 5 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X,y)\n",
    "best_model.predict(T)\n",
    "pred_knn = best_model.predict(T)\n",
    "print(\"MSE: \",mean_squared_error(y_test, pred_knn))\n",
    "print(\"MAE: \",mean_absolute_error(y_test, pred_knn))\n",
    "print(\"R2: \",r2_score(y_test, pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR\n",
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(svr, param_grid={'kernel': ['linear', 'rbf', 'poly'], 'C': [0.1, 1, 10]}, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "X = np.asarray(X_train)\n",
    "y = np.asarray(y_train)\n",
    "T = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate score\n",
    "#### Define score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_svr = SVR(kernel=best_params['kernel'], C=best_params['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate prediction and deduce score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svr = best_svr.predict(T)\n",
    "print(\"MSE: \",mean_squared_error(y_test, pred_svr))\n",
    "print(\"MAE: \",mean_absolute_error(y_test, pred_svr))\n",
    "print(\"R2: \",r2_score(y_test, pred_svr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging, Random Forest, Extra Trees\n",
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred), mean_absolute_error(y_true, y_pred), mean_squared_error(y_true, y_pred)\n",
    "\n",
    "def add_value_in_dict(dict_metrics, model_name, score_metrics):\n",
    "    dict_metrics[model_name] = dict()\n",
    "    dict_metrics[model_name][\"r2_score\"] = score_metrics[0]\n",
    "    dict_metrics[model_name][\"mean_absolute_error\"] = score_metrics[1]\n",
    "    dict_metrics[model_name][\"mean_squared_error\"] = score_metrics[2]\n",
    "\n",
    "def values_from_cross_validate(model, X_train, y_train):\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5,\n",
    "                                 scoring=('r2', 'neg_mean_absolute_error', 'neg_mean_squared_error'))\n",
    "    \n",
    "    del scores['fit_time']\n",
    "    del scores['score_time']\n",
    "\n",
    "    for key, value in scores.items():\n",
    "        scores[key] = [scores[key].mean(), scores[key].std()]\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def grid_search(regressor, param_grid, X, y):\n",
    "    gs = GridSearchCV(regressor, param_grid, cv=5, scoring=['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error'], refit='neg_mean_squared_error', n_jobs=-1)\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    best_params = gs.best_params_\n",
    "    best_regressor = gs.best_estimator_\n",
    "    \n",
    "    print(\"Best Parameters: \", best_params)\n",
    "    print(\"Best Score (neg_mean_squared_error): \", gs.best_score_)\n",
    "\n",
    "    return best_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_adaboost = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "param_grid_bagging = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "}\n",
    "param_grid_extratrees = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "param_grid_gradientboosting = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "param_grid_randomforest = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dict_metrics = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adaboost = grid_search(AdaBoostRegressor(), param_grid_adaboost, X_train, y_train)\n",
    "model_bagging = grid_search(BaggingRegressor(), param_grid_bagging, X_train, y_train)\n",
    "model_extratrees = grid_search(ExtraTreesRegressor(), param_grid_extratrees, X_train, y_train)\n",
    "model_gradientboosting = grid_search(GradientBoostingRegressor(), param_grid_gradientboosting, X_train, y_train)\n",
    "model_randomforest = grid_search(RandomForestRegressor(), param_grid_randomforest, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_value_in_dict(dict_metrics, \"adaboost\", calculate_metrics(y_test, model_adaboost.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics, \"bagging\", calculate_metrics(y_test, model_bagging.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics, \"extratrees\", calculate_metrics(y_test, model_extratrees.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics, \"gradientboosting\", calculate_metrics(y_test, model_gradientboosting.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics, \"randomforest\", calculate_metrics(y_test, model_randomforest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prend le modÃ¨le adaboost qui donne le meilleur MSE<br>\n",
    "On rajoute les valeurs prÃ©dites au testset pour prÃ©dire les causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset[\"retard_moyen_arrivee\"] = model_adaboost.predict(X_test)\n",
    "trainset.rename(columns={\"retard_moyen_arrivee\": \"estimated_retard_moyen\"}, inplace=True)\n",
    "testset.rename(columns={\"retard_moyen_arrivee\": \"estimated_retard_moyen\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['prct_cause_externe', 'prct_cause_infra', 'prct_cause_gestion_trafic','prct_cause_materiel_roulant', 'prct_cause_gestion_gare','prct_cause_prise_en_charge_voyageurs']\n",
    "\n",
    "X_train,y_train = preprocessing(trainset,target,estimated_retard_moyen=True)\n",
    "X_test,y_test = preprocessing(testset,target,estimated_retard_moyen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut prÃ©dire 6 valeurs (les valeurs de probabilitÃ© des causes de retard), cependant nous ne pouvons pas utiliser les rÃ©gresseurs AdaBoost et GradientBoosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metrics_cause = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cause_bagging = grid_search(BaggingRegressor(), param_grid_bagging, X_train, y_train)\n",
    "model_cause_extratrees = grid_search(ExtraTreesRegressor(), param_grid_extratrees, X_train, y_train)\n",
    "model_cause_randomforest = grid_search(RandomForestRegressor(), param_grid_randomforest, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_value_in_dict(dict_metrics_cause, \"bagging\", calculate_metrics(y_test, model_cause_bagging.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics_cause, \"extratrees\", calculate_metrics(y_test, model_cause_extratrees.predict(X_test)))\n",
    "add_value_in_dict(dict_metrics_cause, \"randomforest\", calculate_metrics(y_test, model_cause_randomforest.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metrics_cause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modÃ¨le donnant les meilleurs rÃ©sultats est celui de l'ExtraTrees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
